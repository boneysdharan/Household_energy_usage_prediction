{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = r\"D:\\BONEYS\\WEB\\PYTHON\\Project\\HouseHold_energy_usage\\household_power_consumption.txt\"\n",
    "df_raw = pd.read_csv(path, header=None)\n",
    "\n",
    "#Split the single column into multiple columns using ';' as delimiter\n",
    "df_split = df_raw[0].str.split(';', expand=True)\n",
    "\n",
    "#Set the first row as header\n",
    "df_split.columns = df_split.iloc[0]\n",
    "df_split = df_split.drop(index=0).reset_index(drop=True)\n",
    "\n",
    "#Convert Date and Time columns to proper formats and seperating Datetime to Date and Time Individually\n",
    "df_split['Date'] = pd.to_datetime(df_split['Date'], format='%d/%m/%Y').dt.date\n",
    "df_split['Time'] = pd.to_datetime(df_split['Time'], format='%H:%M:%S').dt.time\n",
    "\n",
    "df_split.to_csv('household_power_consumption.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99ae6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date      Time  Global_active_power  Global_reactive_power  \\\n",
      "4        2006-12-16  17:28:00                3.666                  0.528   \n",
      "5        2006-12-16  17:29:00                3.520                  0.522   \n",
      "6        2006-12-16  17:30:00                3.702                  0.520   \n",
      "7        2006-12-16  17:31:00                3.700                  0.520   \n",
      "8        2006-12-16  17:32:00                3.668                  0.510   \n",
      "...             ...       ...                  ...                    ...   \n",
      "2075254  2010-11-26  20:58:00                0.946                  0.000   \n",
      "2075255  2010-11-26  20:59:00                0.944                  0.000   \n",
      "2075256  2010-11-26  21:00:00                0.938                  0.000   \n",
      "2075257  2010-11-26  21:01:00                0.934                  0.000   \n",
      "2075258  2010-11-26  21:02:00                0.932                  0.000   \n",
      "\n",
      "         Voltage  Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
      "4         235.68              15.8             0.0             1.0   \n",
      "5         235.02              15.0             0.0             2.0   \n",
      "6         235.09              15.8             0.0             1.0   \n",
      "7         235.22              15.8             0.0             1.0   \n",
      "8         233.99              15.8             0.0             1.0   \n",
      "...          ...               ...             ...             ...   \n",
      "2075254   240.43               4.0             0.0             0.0   \n",
      "2075255   240.00               4.0             0.0             0.0   \n",
      "2075256   239.82               3.8             0.0             0.0   \n",
      "2075257   239.70               3.8             0.0             0.0   \n",
      "2075258   239.55               3.8             0.0             0.0   \n",
      "\n",
      "         Sub_metering_3  Daily_Average  Peak_Hour  Voltage_normalized  \\\n",
      "4                  17.0       3.053475         18           -1.592555   \n",
      "5                  17.0       3.053475         18           -1.796260   \n",
      "6                  17.0       3.053475         18           -1.774655   \n",
      "7                  17.0       3.053475         18           -1.734531   \n",
      "8                  17.0       3.053475         18           -2.114162   \n",
      "...                 ...            ...        ...                 ...   \n",
      "2075254             0.0       1.178230          7           -0.126500   \n",
      "2075255             0.0       1.178230          7           -0.259216   \n",
      "2075256             0.0       1.178230          7           -0.314772   \n",
      "2075257             0.0       1.178230          7           -0.351809   \n",
      "2075258             0.0       1.178230          7           -0.398106   \n",
      "\n",
      "         Global_intensity_normalized  \n",
      "4                           2.513781  \n",
      "5                           2.333779  \n",
      "6                           2.513781  \n",
      "7                           2.513781  \n",
      "8                           2.513781  \n",
      "...                              ...  \n",
      "2075254                    -0.141247  \n",
      "2075255                    -0.141247  \n",
      "2075256                    -0.186248  \n",
      "2075257                    -0.186248  \n",
      "2075258                    -0.186248  \n",
      "\n",
      "[2001563 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = r\"D:\\BONEYS\\WEB\\PYTHON\\Project\\HouseHold_energy_usage\\household_power_consumption.csv\"\n",
    "df = pd.read_csv(path,low_memory=False)\n",
    "df = df.ffill()\n",
    "df = df.bfill()\n",
    "\n",
    "# Combine 'Date' and 'Time' into a single datetime column\n",
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Convert Global_active_power to numeric (handle non-numeric values)\n",
    "df['Global_active_power'] = pd.to_numeric(df['Global_active_power'],errors='coerce')\n",
    "\n",
    "# Set DateTime as index\n",
    "df.set_index('DateTime', inplace=True)\n",
    "\n",
    "# Daily Average\n",
    "df['Daily_Average'] = df['Global_active_power'].resample('D').transform('mean')\n",
    "\n",
    "# Peak Hour during the day\n",
    "df['Hour'] = df.index.hour\n",
    "daily_peak_hours = (\n",
    "    df.groupby(['Date', 'Hour'])['Global_active_power']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .sort_values(['Date', 'Global_active_power'], ascending=[True, False])\n",
    "    .drop_duplicates(subset='Date')  # keep only the top hour per date\n",
    "    .rename(columns={'Hour': 'Peak_Hour'})\n",
    ")\n",
    "\n",
    "if 'Peak_Hour' in df.columns:\n",
    "    df = df.drop(columns=['Peak_Hour'])\n",
    "\n",
    "# merge to get Peak Hour during the day\n",
    "df = df.merge(daily_peak_hours[['Date', 'Peak_Hour']], on='Date', how='left')\n",
    "df = df.drop(columns=['Hour'],axis=1)\n",
    "\n",
    "# Convert object columns to numeric, excluding 'Date' and 'Time'\n",
    "cols_to_convert = df.select_dtypes(include='object').columns.drop(['Date', 'Time'])\n",
    "\n",
    "# Apply conversion\n",
    "df[cols_to_convert] = df[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#removing outliners we have 2075259 rows\n",
    "df['Voltage_normalized'] = (df['Voltage']-df['Voltage'].mean())/df['Voltage'].std()\n",
    "df['Global_intensity_normalized'] = (df['Global_intensity']-df['Global_intensity'].mean())/df['Global_intensity'].std()\n",
    "condition1 = df['Voltage_normalized']<=3\n",
    "condition2 = df['Voltage_normalized']>=-3\n",
    "condition3 = df['Global_intensity_normalized']<=3\n",
    "condition4 = df['Global_intensity_normalized']>=-3\n",
    "df = df[(condition1 & condition2 & condition3 & condition4)]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cade2e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2001563 entries, 4 to 2075258\n",
      "Data columns (total 13 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   Date                         object \n",
      " 1   Time                         object \n",
      " 2   Global_active_power          float64\n",
      " 3   Global_reactive_power        float64\n",
      " 4   Voltage                      float64\n",
      " 5   Global_intensity             float64\n",
      " 6   Sub_metering_1               float64\n",
      " 7   Sub_metering_2               float64\n",
      " 8   Sub_metering_3               float64\n",
      " 9   Daily_Average                float64\n",
      " 10  Peak_Hour                    int32  \n",
      " 11  Voltage_normalized           float64\n",
      " 12  Global_intensity_normalized  float64\n",
      "dtypes: float64(10), int32(1), object(2)\n",
      "memory usage: 206.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d5b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: DecisionTreeRegressor\n",
      "Average RMSE: 0.0410\n",
      "Average MAE: 0.0199\n",
      "Average R2 Score: 0.9979\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "Average RMSE: 0.0303\n",
      "Average MAE: 0.0156\n",
      "Average R2 Score: 0.9989\n",
      "\n",
      "Model: LinearRegression\n",
      "Average RMSE: 0.0394\n",
      "Average MAE: 0.0249\n",
      "Average R2 Score: 0.9981\n",
      "\n",
      "Model: KNeighborsRegressor\n",
      "Average RMSE: 0.0404\n",
      "Average MAE: 0.0237\n",
      "Average R2 Score: 0.9980\n"
     ]
    }
   ],
   "source": [
    "#deep learning model evauation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "#getting memory allocation error so reducing size\n",
    "df =df.sample(200000)\n",
    "x = df.drop(['Date', 'Time', 'Global_active_power','Peak_Hour','Voltage_normalized','Global_intensity_normalized'], axis=1)\n",
    "y = df['Global_active_power']\n",
    "\n",
    "models = [\n",
    "    DecisionTreeRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    LinearRegression(),\n",
    "    KNeighborsRegressor(),\n",
    "]\n",
    "\n",
    "evaluation = {\n",
    "    'DecisionTreeRegressor': {'rmse': [], 'mae': [], 'r2': []},\n",
    "    'RandomForestRegressor': {'rmse': [], 'mae': [], 'r2': []},\n",
    "    'LinearRegression': {'rmse': [], 'mae': [], 'r2': []},\n",
    "    'KNeighborsRegressor': {'rmse': [], 'mae': [], 'r2': []}\n",
    "}\n",
    "\n",
    "for i in range(10):\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25)\n",
    "    for model in models:\n",
    "        model.fit(xtrain, ytrain)\n",
    "        predictions = model.predict(xtest)\n",
    "\n",
    "        rmse = root_mean_squared_error(ytest, predictions)\n",
    "        mae = mean_absolute_error(ytest, predictions)\n",
    "        r2 = r2_score(ytest, predictions)\n",
    "\n",
    "        evaluation[type(model).__name__]['rmse'].append(rmse)\n",
    "        evaluation[type(model).__name__]['mae'].append(mae)\n",
    "        evaluation[type(model).__name__]['r2'].append(r2)\n",
    "\n",
    "# Print average metrics\n",
    "for model_name, metrics in evaluation.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Average RMSE: {np.mean(metrics['rmse']):.4f}\")\n",
    "    print(f\"Average MAE: {np.mean(metrics['mae']):.4f}\")\n",
    "    print(f\"Average R2 Score: {np.mean(metrics['r2']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe0b8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Performance:\n",
      "R2: 0.9987\n",
      "RMSE: 0.0325\n",
      "MAE: 0.0201\n",
      "\n",
      "Test Performance:\n",
      "R2: 0.9987\n",
      "RMSE: 0.0324\n",
      "MAE: 0.0200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "# 1. Sample and split data\n",
    "df = df.sample(200000)\n",
    "x = df.drop(['Date', 'Time', 'Global_active_power', 'Peak_Hour', 'Voltage_normalized', 'Global_intensity_normalized'], axis=1)\n",
    "y = df['Global_active_power']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# 2. Convert to PyTorch tensors\n",
    "xtrain = torch.tensor(xtrain.values, dtype=torch.float32)\n",
    "ytrain = torch.tensor(ytrain.values, dtype=torch.float32)\n",
    "xtest = torch.tensor(xtest.values, dtype=torch.float32)\n",
    "ytest = torch.tensor(ytest.values, dtype=torch.float32)\n",
    "\n",
    "# 3. Create Dataset and DataLoader\n",
    "train_dataset = TensorDataset(xtrain, ytrain)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# 4. Define Neural Network\n",
    "class DeepNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DeepNN, self).__init__()\n",
    "        self.input = nn.Linear(input_dim, 64)\n",
    "        self.hidden1 = nn.Linear(64, 32)\n",
    "        self.hidden2 = nn.Linear(32, 16)\n",
    "        self.hidden3 = nn.Linear(16, 8)\n",
    "        self.output = nn.Linear(8, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input(x))\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.relu(self.hidden3(x))\n",
    "        return self.output(x)\n",
    "\n",
    "# 5. Model, loss, optimizer\n",
    "model = DeepNN(xtrain.shape[1], 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 6. Training\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for x_train, y_train in train_loader:\n",
    "        y_train = y_train.view(-1, 1)\n",
    "        pred = model(x_train)\n",
    "        loss = criterion(pred, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 7. Evaluation\n",
    "with torch.no_grad():\n",
    "    train_preds = model(xtrain).squeeze()\n",
    "    test_preds = model(xtest).squeeze()\n",
    "\n",
    "    print(\"\\nTrain Performance:\")\n",
    "    print(f\"R2: {r2_score(ytrain, train_preds):.4f}\")\n",
    "    print(f\"RMSE: {root_mean_squared_error(ytrain, train_preds):.4f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(ytrain, train_preds):.4f}\")\n",
    "\n",
    "    print(\"\\nTest Performance:\")\n",
    "    print(f\"R2: {r2_score(ytest, test_preds):.4f}\")\n",
    "    print(f\"RMSE: {root_mean_squared_error(ytest, test_preds):.4f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(ytest, test_preds):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ed1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
